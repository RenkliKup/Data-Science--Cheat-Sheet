{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-4fwv_Ro6Oc87DtH2JZgMbdFzBTdG5N0",
      "authorship_tag": "ABX9TyOS7DwoLShKkx4xls3g7Aqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RenkliKup/Data-Science--Cheat-Sheet/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya8qcCmzUlYw",
        "outputId": "7c0db722-8fb2-420e-f579-4bb5d6f51036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "S39KTPPq3tI1"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"gpu not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sme1bhl7ibZS",
        "outputId": "62f9ad20-6ac1-4d88-de2b-7ea955265562"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QswtTqMerjS2"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/Sentiment_dataset.csv',sep=\",\",engine='python')\n",
        "\n"
      ],
      "metadata": {
        "id": "OOeAIY0Kinw1"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop([\"news_title\",\"reddit_title\",\"url\"],axis=1)"
      ],
      "metadata": {
        "id": "w7uZrltu6XTe"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded_sentiment'] = LabelEncoder().fit_transform(df['sentiment'])"
      ],
      "metadata": {
        "id": "5k3xUEZE550D"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "1oGynjULrvcJ",
        "outputId": "add73c8c-1035-4504-c119-46f086a380db"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentiment                                               text  \\\n",
              "504        1.0  Jess Wade is a scientist on a mission. She wan...   \n",
              "192        1.0  U.S. President Donald Trump signed a measure t...   \n",
              "97         1.0  When a young Birmingham college student's car ...   \n",
              "703        1.0  Some containers have all the sun. These shady ...   \n",
              "116        1.0  UPDATE 5th September 2017: Warner Bros. has is...   \n",
              "591        1.0  \\n\\n\\n\\nBy Lee Min-hyung\\n\\n\\n\\n\\n\\n\\n\\nThe tw...   \n",
              "191        1.0  Michael Platt, a 13-year-old who lives in Wash...   \n",
              "715        1.0  NEW YORK -- The high-security trial of infamou...   \n",
              "91         1.0  Animal lovers wonâ€™t be able to buy that fluffy...   \n",
              "164        1.0  Tony Lethbridge was determined not to let his ...   \n",
              "\n",
              "     encoded_sentiment  \n",
              "504                  1  \n",
              "192                  1  \n",
              "97                   1  \n",
              "703                  1  \n",
              "116                  1  \n",
              "591                  1  \n",
              "191                  1  \n",
              "715                  1  \n",
              "91                   1  \n",
              "164                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1692a1b1-dc37-489a-bc3b-a70d47eabbd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Jess Wade is a scientist on a mission. She wan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1.0</td>\n",
              "      <td>U.S. President Donald Trump signed a measure t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1.0</td>\n",
              "      <td>When a young Birmingham college student's car ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Some containers have all the sun. These shady ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>1.0</td>\n",
              "      <td>UPDATE 5th September 2017: Warner Bros. has is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>1.0</td>\n",
              "      <td>\\n\\n\\n\\nBy Lee Min-hyung\\n\\n\\n\\n\\n\\n\\n\\nThe tw...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Michael Platt, a 13-year-old who lives in Wash...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NEW YORK -- The high-security trial of infamou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Animal lovers wonâ€™t be able to buy that fluffy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Tony Lethbridge was determined not to let his ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1692a1b1-dc37-489a-bc3b-a70d47eabbd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1692a1b1-dc37-489a-bc3b-a70d47eabbd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1692a1b1-dc37-489a-bc3b-a70d47eabbd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('sentiment').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kodbMP1rx85",
        "outputId": "2cf241df-9f04-4d04-c0f0-9d7a67dd2b26"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "0.0    100\n",
              "1.0    748\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,TFBertModel"
      ],
      "metadata": {
        "id": "b-KSa7ySEQKt"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)\n",
        "sentences = df.text.values\n",
        "max_len = 250"
      ],
      "metadata": {
        "id": "YqHkNHS7r0ev"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training = df.groupby('sentiment').apply(lambda x : x.sample(frac = 1))\n",
        "test = pd.concat([df,training]).drop_duplicates(keep=False)\n",
        "\n",
        "print(\"Training: \", len(training))\n",
        "print(\"Test: \", len(test))\n",
        "\n",
        "training_texts = training.text.values\n",
        "training_labels = training.encoded_sentiment.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqyH0A0lsCPE",
        "outputId": "d37389e6-cc33-4685-c149-8e46acd709df"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  848\n",
            "Test:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "gT5vgG-XsHh3",
        "outputId": "1b287303-8f68-4a3e-f8e4-ba2eb57a23b8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               sentiment                                               text  \\\n",
              "sentiment                                                                     \n",
              "0.0       800        0.0  California's Camp Fire Becomes The Deadliest W...   \n",
              "          786        0.0  A city in China has banned pet owners from wal...   \n",
              "          847        0.0  HONG KONG (AFP) - Five people were killed and ...   \n",
              "          799        0.0  Hate crimes in the U.S. rose about 17 percent ...   \n",
              "          751        0.0  By Dan Whitcomb\\n\\nLOS ANGELES (Reuters) - Mod...   \n",
              "...                  ...                                                ...   \n",
              "1.0       712        1.0  W hat do you use your Amazon Echo for? To list...   \n",
              "          615        1.0  Frequent 911 calls from chronically ill city r...   \n",
              "          714        1.0  A 'meat tax' on bacon, burgers and beef could ...   \n",
              "          498        1.0  The Mayor of Flavortown is giving back to rest...   \n",
              "          313        1.0  Durban - A specialised unit, set up to fight p...   \n",
              "\n",
              "               encoded_sentiment  \n",
              "sentiment                         \n",
              "0.0       800                  0  \n",
              "          786                  0  \n",
              "          847                  0  \n",
              "          799                  0  \n",
              "          751                  0  \n",
              "...                          ...  \n",
              "1.0       712                  1  \n",
              "          615                  1  \n",
              "          714                  1  \n",
              "          498                  1  \n",
              "          313                  1  \n",
              "\n",
              "[848 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a6a91d8-97db-4186-87a8-0e6fd045ccf6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
              "      <th>800</th>\n",
              "      <td>0.0</td>\n",
              "      <td>California's Camp Fire Becomes The Deadliest W...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>0.0</td>\n",
              "      <td>A city in China has banned pet owners from wal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>0.0</td>\n",
              "      <td>HONG KONG (AFP) - Five people were killed and ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Hate crimes in the U.S. rose about 17 percent ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>0.0</td>\n",
              "      <td>By Dan Whitcomb\\n\\nLOS ANGELES (Reuters) - Mod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
              "      <th>712</th>\n",
              "      <td>1.0</td>\n",
              "      <td>W hat do you use your Amazon Echo for? To list...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Frequent 911 calls from chronically ill city r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A 'meat tax' on bacon, burgers and beef could ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The Mayor of Flavortown is giving back to rest...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Durban - A specialised unit, set up to fight p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>848 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a6a91d8-97db-4186-87a8-0e6fd045ccf6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a6a91d8-97db-4186-87a8-0e6fd045ccf6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a6a91d8-97db-4186-87a8-0e6fd045ccf6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "X_train=tokenizer(\n",
        "    text=training_texts.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        "    verbose=True\n",
        ")\n",
        "\"\"\"\n",
        "for text in training_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 100,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "\n",
        "labels = training_labels\n",
        "\n",
        "print('Original: ', training_texts[0])\n",
        "print('Token IDs:', input_ids[0])\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "x1dBF2YGsJlH",
        "outputId": "8b25cc24-d5ea-47fd-c9ea-4723928747ba"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor text in training_texts:\\n    encoded_dict = tokenizer.encode_plus(\\n                        text,                     \\n                        add_special_tokens = True,\\n                        max_length = 100,      \\n                        pad_to_max_length = True,\\n                        return_attention_mask = True, \\n                        return_tensors = 'pt',\\n                   )\\n    \\n    input_ids.append(encoded_dict['input_ids'])\\n    attention_masks.append(encoded_dict['attention_mask'])\\n\\n\\n\\nlabels = training_labels\\n\\nprint('Original: ', training_texts[0])\\nprint('Token IDs:', input_ids[0])\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = TFBertModel.from_pretrained('dbmdz/bert-base-turkish-128k-uncased')\n",
        "\"\"\"train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\"\"\"\n",
        "batch_size = 32\n",
        "number_of_categories = len(df['encoded_sentiment'].unique())\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
        "    num_labels = number_of_categories,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBP7mDTjsxta",
        "outputId": "080276e4-2cc2-494c-9afd-d54b21dc6dc3"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "# embeddings = dbert_model(input_ids, attention_mask = input_mask)[0]\n",
        "\n",
        "embeddings = bert(input_ids, attention_mask = input_mask)[0] # 0 = last hidden state, 1 = poller_output\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32, activation='relu')(out)\n",
        "\n",
        "y = Dense(2, activation='softmax')(out)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True\n",
        "\n",
        "\n",
        "loss = CategoricalCrossentropy(from_logits=True)\n",
        "metric = CategoricalAccuracy('balanced_accuracy')\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "    loss=loss,\n",
        "    metrics=metric\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "6p7QwvG9JDsV"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
        "    y = to_categorical(training_labels),\n",
        "    epochs=4,\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK_2WxLBJoun",
        "outputId": "83db5c53-b62e-4841-adcc-c6ede9337426"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "43/43 [==============================] - 65s 831ms/step - loss: 0.5209 - balanced_accuracy: 0.8230\n",
            "Epoch 2/4\n",
            "43/43 [==============================] - 37s 851ms/step - loss: 0.3978 - balanced_accuracy: 0.8820\n",
            "Epoch 3/4\n",
            "43/43 [==============================] - 38s 883ms/step - loss: 0.3755 - balanced_accuracy: 0.8820\n",
            "Epoch 4/4\n",
            "43/43 [==============================] - 38s 883ms/step - loss: 0.3758 - balanced_accuracy: 0.8820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predicted = model.predict({'input_ids': X_train['input_ids'], 'attention_mask': X_train['attention_mask']})\n",
        "y_predicted = np.argmax(predicted, axis=1)\n",
        "print(classification_report(training_labels, y_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ9APSjOKsta",
        "outputId": "fdd770e4-e4cb-4a58-8056-ed9626d96d6b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 15s 526ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        80\n",
            "           1       0.88      1.00      0.94       598\n",
            "\n",
            "    accuracy                           0.88       678\n",
            "   macro avg       0.44      0.50      0.47       678\n",
            "weighted avg       0.78      0.88      0.83       678\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_cc6eRTM8U0",
        "outputId": "7386ff69-91ee-423f-950e-0aef42402b29"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnKqHnihNAyv",
        "outputId": "697021f6-de5c-4fcf-bf18-ba72dbde3a30"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "history = model.fit(\n",
        "    x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
        "    y = to_categorical(training_labels),\n",
        "    epochs=1,\n",
        "    batch_size=2,verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "gPXwg-8vBE7A",
        "outputId": "16bab8db-59cd-441c-ffad-91ad45bd4a27"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-bdfc6d5daf1e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiuYiEdSuiPr",
        "outputId": "3b0888f9-d4aa-4513-bc23-1caf31addb41"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.co"
      ],
      "metadata": {
        "id": "vUjEVSOu3kAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 1903\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        output = model(b_input_ids,\n",
        "                       token_type_ids=None,\n",
        "                       attention_mask=b_input_mask,\n",
        "                       labels=b_labels)\n",
        "        loss = output['loss']\n",
        "        logits = output['logits']\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpGuCCIrtv9k",
        "outputId": "0bb1a361-38d5-4f8a-b458-65b012116e20"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Epoch 1 / 4 ========\n",
            "Batch    10  of     57.    Elapsed: 0:00:18.\n",
            "Batch    20  of     57.    Elapsed: 0:00:33.\n",
            "Batch    30  of     57.    Elapsed: 0:00:49.\n",
            "Batch    40  of     57.    Elapsed: 0:01:04.\n",
            "Batch    50  of     57.    Elapsed: 0:01:19.\n",
            "Average training loss: 0.56\n",
            "Training epoch took: 0:01:28\n",
            "======== Epoch 2 / 4 ========\n",
            "Batch    10  of     57.    Elapsed: 0:00:15.\n",
            "Batch    20  of     57.    Elapsed: 0:00:30.\n",
            "Batch    30  of     57.    Elapsed: 0:00:45.\n",
            "Batch    40  of     57.    Elapsed: 0:01:00.\n",
            "Batch    50  of     57.    Elapsed: 0:01:15.\n",
            "Average training loss: 0.18\n",
            "Training epoch took: 0:01:25\n",
            "======== Epoch 3 / 4 ========\n",
            "Batch    10  of     57.    Elapsed: 0:00:15.\n",
            "Batch    20  of     57.    Elapsed: 0:00:30.\n",
            "Batch    30  of     57.    Elapsed: 0:00:45.\n",
            "Batch    40  of     57.    Elapsed: 0:01:00.\n",
            "Batch    50  of     57.    Elapsed: 0:01:15.\n",
            "Average training loss: 0.07\n",
            "Training epoch took: 0:01:25\n",
            "======== Epoch 4 / 4 ========\n",
            "Batch    10  of     57.    Elapsed: 0:00:15.\n",
            "Batch    20  of     57.    Elapsed: 0:00:30.\n",
            "Batch    30  of     57.    Elapsed: 0:00:45.\n",
            "Batch    40  of     57.    Elapsed: 0:01:00.\n",
            "Batch    50  of     57.    Elapsed: 0:01:15.\n",
            "Average training loss: 0.03\n",
            "Training epoch took: 0:01:25\n",
            "Training completed in 0:05:43 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "EGHouGzZuYU3",
        "outputId": "38a7b421-6a8b-4757-f266-50f08a6d2f39"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = test.text.values\n",
        "test_labels = test.encoded_categories.values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in test_texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = max_len,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt3y7JxgvOtQ",
        "outputId": "29a98683-eb0c-4c1b-eb9c-f873eed6bfb1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction started on test data')\n",
        "model.eval()\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('Prediction completed')\n",
        "\n",
        "prediction_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  prediction_set.append(pred_labels_i)\n",
        "\n",
        "prediction_scores = [item for sublist in prediction_set for item in sublist]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3awZqelwBzf",
        "outputId": "11b05509-0fa6-401d-e3cc-3458ac18fdd0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction started on test data\n",
            "Prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
        "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
        "recall = recall_score(test_labels, prediction_scores, average='macro')\n",
        "\n",
        "print(\"F-Score: \", f_score)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))\n",
        "report = report.rename(columns={'0':'dunya',\n",
        "                          '1':'ekonomi',\n",
        "                          '2':'kultur',\n",
        "                          '3':'saglik',\n",
        "                          '4':'siyaset',\n",
        "                          '5':'spor',\n",
        "                          '6':'teknoloji'})\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLl5taAuwG3V",
        "outputId": "c937867a-b93c-45be-8464-ce329f7f42fa"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Score:  0.9401014372538683\n",
            "Recall:  0.9336514778325122\n",
            "Precision:  0.9472371054364899\n",
            "                dunya     ekonomi     kultur      saglik  accuracy  \\\n",
            "precision    0.906977    0.948148   1.000000    0.933824  0.934426   \n",
            "recall       0.928571    0.941176   0.931034    0.933824  0.934426   \n",
            "f1-score     0.917647    0.944649   0.964286    0.933824  0.934426   \n",
            "support    126.000000  136.000000  29.000000  136.000000  0.934426   \n",
            "\n",
            "            macro avg  weighted avg  \n",
            "precision    0.947237      0.934958  \n",
            "recall       0.933651      0.934426  \n",
            "f1-score     0.940101      0.934567  \n",
            "support    427.000000    427.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIsQ8AckwNTw",
        "outputId": "f24857f4-15ab-41f2-c6f9-d34bb208eabc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     2,   5616,     41,   5739,  27178,   1972,  12312,   1985,   3741,\n",
              "         105003,   1927,   3276,  27178,   4347,   3741,   2893,  58688,   1925,\n",
              "          22918,   1961,  15500,   2185,   2692, 108723,   1946,  18163,   1972,\n",
              "           1972,  15886,  24644,  19004, 125901,  60304,   1943,   5616,     41,\n",
              "           5739,     43,  12312,   1985,   3772,   7458,   1956,   2630,   5739,\n",
              "          12312,   1985,  40209,   5692,  16316,  19000,  22328,  21414,   2693,\n",
              "           2791,   1946,  56642,   2884,  10845,  10262,   8804,   2741,   5561,\n",
              "           1946,   5970,  14040,   3512,  34935,   8117,   1947,  46179,   2485,\n",
              "           7757,   7099,  26470,  11497,  80447,  27178,   2325,   2064,  41541,\n",
              "          56642,   1937,  67469,   2120,   3509,  79166,  20026,   9705,   2052,\n",
              "          12312,  29612,   2308,   2276,   5970,   1946,   5382,   9662,   1964,\n",
              "           2124,   2382,   3098,   1947,   6142,  60304,   1943,  12312,  17598,\n",
              "          10109,   8178,   5560,   2960,   9072,   1964,   4391,  54080,   2956,\n",
              "           1946,  15909,   2919,  18431,  99285,   6337,   1947,  29622,   5138,\n",
              "           8668,   5557,  79166,  20026,   9705,   2052,   2683,  13514,  17362,\n",
              "           2120,  12312,   1985,   2039,   2095,  29024,   1934,   4245,  15741,\n",
              "           9716,  20382,  28852, 119414,   5919,   3736,   5616,     41,   5739,\n",
              "             43,   5799,   5728,  55011,   2125,  18431,   3736,  70154,  10888,\n",
              "          73618,  43529,  69999,   4220,  16465,   1007,  45994,  14337,   1007,\n",
              "          84105, 101382,  26435,   6861,  71329,  54080,   2956,  12312,   1985,\n",
              "           4923,   2597,   1011,   3000,   3736,   2120,  76052,  15406,   1927,\n",
              "             41,  24432,  23619,   8872,   2664,   5554,   5616,     41,   5739,\n",
              "           6676,  27178,   2642,   2759,  46076,   1944,  55971,   2682,  67408,\n",
              "           6110,   4928,   6337,  24733,   2037,  56642,   1946,  99530,  40395,\n",
              "          10088,  93128,   1961,  67838,  50850,   5554,   2893,   4923,   8745,\n",
              "          12312,   2854,   5558,  44523,   5561,   9563,   1946,   9861,  40395,\n",
              "           8780,   6196,  17362,   6330, 125720,   1007,   6052,   4447,  16870,\n",
              "          46157,   2642,   3741,   5739,  14877,  12312,      3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcfoshbwwgDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}